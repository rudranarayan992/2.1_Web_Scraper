import requestsfrom bs4 import BeautifulSoupimport json  url = 'https://github.com/psf/requests'    payload = {    'api_key': 'YOUR_API_KEY',     'url': url,     'render': 'true',           }  page = requests.get('https://api.scraperapi.com', params=payload)  soup = BeautifulSoup(page.text, 'html.parser')  repo = {}  name_html_element = soup.find('strong', {"itemprop": "name"})repo['name'] = name_html_element.get_text().strip()  relative_time_html_element = soup.find('relative-time')repo['latest_commit'] = relative_time_html_element['datetime']  branch_element = soup.find('span', {"class": "Text-sc-17v1xeu-0 bOMzPg"})repo['branch'] = branch_element.get_text().strip()  commit_element = soup.find('span', {"class": "Text-sc-17v1xeu-0 gPDEWA fgColor-default"})repo['commit'] = commit_element.get_text().strip()  stars_element = soup.find('span', {"id": "repo-stars-counter-star"})repo['stars'] = stars_element.get_text().strip()  forks_element = soup.find('span', {"id": "repo-network-counter"})repo['forks'] = forks_element.get_text().strip()  description_html_element = soup.find('p', {"class":"f4 my-3"})repo['description'] = description_html_element.get_text().strip()  main_branch = repo['branch']readme_url = f'https://raw.githubusercontent.com/psf/requests/{main_branch}/README.md'readme_page = requests.get(readme_url)      if readme_page.status_code != 404:    repo['readme'] = readme_page.text  print(repo)  with open('repo.json', 'w') as file:    json.dump(repo, file, indent=4)  print('Data saved to repo.json')
